{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dlt Exploration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a heavily commented section intended to help the understanding of the code and how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL of the API, ENDPOINT, and STARTING_PAGE\n",
    "BASE_URL = \"https://us-central1-dlthub-analytics.cloudfunctions.net\"\n",
    "ENDPOINT = \"data_engineering_zoomcamp_api\"\n",
    "STARTING_PAGE = 1\n",
    "\n",
    "# define a function that returns a paginated getter\n",
    "def paginated_getter():\n",
    "    # create a REST client with the base URL and a page number paginator\n",
    "    client = RESTClient(\n",
    "        base_url=BASE_URL,\n",
    "        paginator=PageNumberPaginator(\n",
    "          base_page=STARTING_PAGE,  # Start pagination from page 1\n",
    "          total_path=None  # No total count path, paginate until no more pages\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Iterate over each page of data from the API using the client\n",
    "    for page in client.paginate(ENDPOINT):\n",
    "        yield page  # Yield each page of data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 - Total records: 1000\n"
     ]
    }
   ],
   "source": [
    "page_num = STARTING_PAGE\n",
    "# Iterate over each page of data\n",
    "for page_data in paginated_getter():\n",
    "    if page_num == STARTING_PAGE:\n",
    "      # Store the first record as a sample for reference\n",
    "      sample_record = json.dumps(page_data[0], indent=2)\n",
    "    \n",
    "    # Print the total records on each page   \n",
    "    print(f\"Page {page_num} - Total records: {len(page_data)}\")\n",
    "    page_num+=1\n",
    "    break # For a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Record: \n",
      " {\n",
      "  \"End_Lat\": 40.742963,\n",
      "  \"End_Lon\": -73.980072,\n",
      "  \"Fare_Amt\": 45.0,\n",
      "  \"Passenger_Count\": 1,\n",
      "  \"Payment_Type\": \"Credit\",\n",
      "  \"Rate_Code\": null,\n",
      "  \"Start_Lat\": 40.641525,\n",
      "  \"Start_Lon\": -73.787442,\n",
      "  \"Tip_Amt\": 9.0,\n",
      "  \"Tolls_Amt\": 4.15,\n",
      "  \"Total_Amt\": 58.15,\n",
      "  \"Trip_Distance\": 17.52,\n",
      "  \"Trip_Dropoff_DateTime\": \"2009-06-14 23:48:00\",\n",
      "  \"Trip_Pickup_DateTime\": \"2009-06-14 23:23:00\",\n",
      "  \"mta_tax\": null,\n",
      "  \"store_and_forward\": null,\n",
      "  \"surcharge\": 0.0,\n",
      "  \"vendor_name\": \"VTS\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the sample record\n",
    "print(\"Sample Record: \\n\", sample_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"ny_taxi_data\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the \"rides\" table in DuckDB, replacing any existing data.\n",
    "load_info = pipeline.run(\n",
    "  paginated_getter(),  # The generator function that retrieves paginated data\n",
    "  table_name=\"rides\",  # Specify the target table name\n",
    "  write_disposition=\"replace\",  # Replace the existing data in the table\n",
    ")\n",
    "\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit info\n",
    "!dlt pipeline ny_taxi_pipeline show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in duckdb\n",
    "\n",
    "As expected, 10,000 rows on duckDb\n",
    "\n",
    "![](assets/images/image.png)\n",
    "\n",
    "And the json file properly dumped into duckDb\n",
    "\n",
    "| Index | name                   | data_type | nullable |\n",
    "|-------|------------------------|-----------|----------|\n",
    "| 0     | end_lat                | double    | true     |\n",
    "| 1     | end_lon                | double    | true     |\n",
    "| 2     | fare_amt               | double    | true     |\n",
    "| 3     | passenger_count        | bigint    | true     |\n",
    "| 4     | payment_type           | text      | true     |\n",
    "| 5     | start_lat              | double    | true     |\n",
    "| 6     | start_lon              | double    | true     |\n",
    "| 7     | tip_amt                | double    | true     |\n",
    "| 8     | tolls_amt              | double    | true     |\n",
    "| 9     | total_amt              | double    | true     |\n",
    "| 10    | trip_distance          | double    | true     |\n",
    "| 11    | trip_dropoff_date_time | timestamp | true     |\n",
    "| 12    | trip_pickup_date_time  | timestamp | true     |\n",
    "| 13    | surcharge              | double    | true     |\n",
    "| 14    | vendor_name            | text      | true     |\n",
    "| 15    | _dlt_load_id           | text      | false    |\n",
    "| 16    | _dlt_id                | text      | false    |\n",
    "| 17    | store_and_forward      | double    | true     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dlt decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "# Define the base URL of the API, ENDPOINT, and STARTING_PAGE\n",
    "BASE_URL = \"https://us-central1-dlthub-analytics.cloudfunctions.net\"\n",
    "ENDPOINT = \"data_engineering_zoomcamp_api\"\n",
    "STARTING_PAGE = 1\n",
    "\n",
    "# Define the API resource for NYC taxi data\n",
    "@dlt.resource(name=\"decorated_rides\")   # <--- The name of the resource (will be used as the table name if none provided)\n",
    "def ny_taxi():\n",
    "    # Create a REST client with the base URL and a page number paginator\n",
    "    client = RESTClient(\n",
    "        base_url=BASE_URL,\n",
    "        paginator=PageNumberPaginator(\n",
    "          base_page=STARTING_PAGE,  # Start pagination from page 1\n",
    "          total_path=None  # No total count path, paginate until no more pages\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Iterate over each page of data from the API using the client\n",
    "    for page in client.paginate(ENDPOINT):    # <--- API endpoint for retrieving taxi ride data\n",
    "        yield page   # <--- yield data to manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"decorated_ny_taxi_pipeline\", \n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"decorated_ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(\n",
    "  ny_taxi,\n",
    "  write_disposition=\"replace\",\n",
    "  # table_name=\"decorated_rides\" # Optional \n",
    ")\n",
    "\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit info\n",
    "!dlt pipeline decorated_ny_taxi_pipeline show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>fare_amt</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>tip_amt</th>\n",
       "      <th>tolls_amt</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_dropoff_date_time</th>\n",
       "      <th>trip_pickup_date_time</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>store_and_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.742963</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2009-06-14 23:48:00+00:00</td>\n",
       "      <td>2009-06-14 23:23:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>XJrLSClDEwajoQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.740187</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2009-06-18 17:43:00+00:00</td>\n",
       "      <td>2009-06-18 17:35:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>DiF290VyRZe5xA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.718043</td>\n",
       "      <td>-74.004745</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.761945</td>\n",
       "      <td>-73.983038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2009-06-10 18:27:00+00:00</td>\n",
       "      <td>2009-06-10 18:08:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>0Cgm+EQcDKtziw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.739637</td>\n",
       "      <td>-73.985233</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.749802</td>\n",
       "      <td>-73.992247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2009-06-14 23:58:00+00:00</td>\n",
       "      <td>2009-06-14 23:54:00+00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>/8hM0nihcXj6pA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.730032</td>\n",
       "      <td>-73.852693</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.776825</td>\n",
       "      <td>-73.949233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.85</td>\n",
       "      <td>11.09</td>\n",
       "      <td>2009-06-13 13:23:00+00:00</td>\n",
       "      <td>2009-06-13 13:01:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>eZ0GVT4KfsuakA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>40.783522</td>\n",
       "      <td>-73.970690</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.778560</td>\n",
       "      <td>-73.953660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2009-06-19 11:28:00+00:00</td>\n",
       "      <td>2009-06-19 11:22:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>FwZY/ECCDFiRyg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>40.777200</td>\n",
       "      <td>-73.964197</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.779800</td>\n",
       "      <td>-73.974297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2009-06-17 07:43:00+00:00</td>\n",
       "      <td>2009-06-17 07:41:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>2oqiFRUCIauBRA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>40.780172</td>\n",
       "      <td>-73.957617</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.788388</td>\n",
       "      <td>-73.976758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2009-06-19 11:46:00+00:00</td>\n",
       "      <td>2009-06-19 11:39:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>5Lr9pCI2CNcHhg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>40.777342</td>\n",
       "      <td>-73.957242</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>40.773828</td>\n",
       "      <td>-73.956690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2009-06-17 04:19:00+00:00</td>\n",
       "      <td>2009-06-17 04:13:00+00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>0/CXu6RtYCuZ4Q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>40.757122</td>\n",
       "      <td>-73.986293</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.756313</td>\n",
       "      <td>-73.972948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2009-06-17 08:34:00+00:00</td>\n",
       "      <td>2009-06-17 08:24:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1739553950.1613045</td>\n",
       "      <td>753RWSfrgRFpFg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        end_lat    end_lon  fare_amt  passenger_count payment_type  start_lat  \\\n",
       "0     40.742963 -73.980072      45.0                1       Credit  40.641525   \n",
       "1     40.740187 -74.005698       6.5                1       Credit  40.722065   \n",
       "2     40.718043 -74.004745      12.5                5       Credit  40.761945   \n",
       "3     40.739637 -73.985233       4.9                1         CASH  40.749802   \n",
       "4     40.730032 -73.852693      25.7                1         CASH  40.776825   \n",
       "...         ...        ...       ...              ...          ...        ...   \n",
       "9995  40.783522 -73.970690       5.7                1         CASH  40.778560   \n",
       "9996  40.777200 -73.964197       4.1                1         CASH  40.779800   \n",
       "9997  40.780172 -73.957617       6.1                1         CASH  40.788388   \n",
       "9998  40.777342 -73.957242       5.7                1         CASH  40.773828   \n",
       "9999  40.757122 -73.986293       6.5                1       Credit  40.756313   \n",
       "\n",
       "      start_lon  tip_amt  tolls_amt  total_amt  trip_distance  \\\n",
       "0    -73.787442      9.0       4.15      58.15          17.52   \n",
       "1    -74.009767      1.0       0.00       8.50           1.56   \n",
       "2    -73.983038      2.0       0.00      15.50           3.37   \n",
       "3    -73.992247      0.0       0.00       5.40           1.11   \n",
       "4    -73.949233      0.0       4.15      29.85          11.09   \n",
       "...         ...      ...        ...        ...            ...   \n",
       "9995 -73.953660      0.0       0.00       5.70           1.16   \n",
       "9996 -73.974297      0.0       0.00       4.10           0.89   \n",
       "9997 -73.976758      0.0       0.00       6.10           1.30   \n",
       "9998 -73.956690      0.0       0.00       6.20           0.97   \n",
       "9999 -73.972948      2.0       0.00       8.50           0.92   \n",
       "\n",
       "        trip_dropoff_date_time     trip_pickup_date_time  surcharge  \\\n",
       "0    2009-06-14 23:48:00+00:00 2009-06-14 23:23:00+00:00        0.0   \n",
       "1    2009-06-18 17:43:00+00:00 2009-06-18 17:35:00+00:00        1.0   \n",
       "2    2009-06-10 18:27:00+00:00 2009-06-10 18:08:00+00:00        1.0   \n",
       "3    2009-06-14 23:58:00+00:00 2009-06-14 23:54:00+00:00        0.5   \n",
       "4    2009-06-13 13:23:00+00:00 2009-06-13 13:01:00+00:00        0.0   \n",
       "...                        ...                       ...        ...   \n",
       "9995 2009-06-19 11:28:00+00:00 2009-06-19 11:22:00+00:00        0.0   \n",
       "9996 2009-06-17 07:43:00+00:00 2009-06-17 07:41:00+00:00        0.0   \n",
       "9997 2009-06-19 11:46:00+00:00 2009-06-19 11:39:00+00:00        0.0   \n",
       "9998 2009-06-17 04:19:00+00:00 2009-06-17 04:13:00+00:00        0.5   \n",
       "9999 2009-06-17 08:34:00+00:00 2009-06-17 08:24:00+00:00        0.0   \n",
       "\n",
       "     vendor_name        _dlt_load_id         _dlt_id  store_and_forward  \n",
       "0            VTS  1739553950.1613045  XJrLSClDEwajoQ                NaN  \n",
       "1            VTS  1739553950.1613045  DiF290VyRZe5xA                NaN  \n",
       "2            VTS  1739553950.1613045  0Cgm+EQcDKtziw                NaN  \n",
       "3            VTS  1739553950.1613045  /8hM0nihcXj6pA                NaN  \n",
       "4            VTS  1739553950.1613045  eZ0GVT4KfsuakA                NaN  \n",
       "...          ...                 ...             ...                ...  \n",
       "9995         VTS  1739553950.1613045  FwZY/ECCDFiRyg                NaN  \n",
       "9996         VTS  1739553950.1613045  2oqiFRUCIauBRA                NaN  \n",
       "9997         VTS  1739553950.1613045  5Lr9pCI2CNcHhg                NaN  \n",
       "9998         VTS  1739553950.1613045  0/CXu6RtYCuZ4Q                NaN  \n",
       "9999         VTS  1739553950.1613045  753RWSfrgRFpFg                NaN  \n",
       "\n",
       "[10000 rows x 18 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Optionally, explore loaded data\n",
    "# pipeline.dataset(dataset_type=\"default\").decorated_rides.df().info()\n",
    "pipeline.dataset(dataset_type=\"default\").decorated_rides.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "# Define the base URL of the API, ENDPOINT, and STARTING_PAGE\n",
    "BASE_URL = \"https://us-central1-dlthub-analytics.cloudfunctions.net\"\n",
    "ENDPOINT = \"data_engineering_zoomcamp_api\"\n",
    "STARTING_PAGE = 1\n",
    "\n",
    "# Define the API resource for NYC taxi data and the incremental cursor\n",
    "@dlt.resource(name=\"rides\", write_disposition=\"append\")   # <--- The name of the resource (will be used as the table name)\n",
    "def ny_taxi(\n",
    "    cursor_date = dlt.sources.incremental(\n",
    "        \"Trip_Dropoff_DateTime\",   # <--- field to track, our timestamp\n",
    "        initial_value=\"2009-06-15\",   # <--- start date June 15, 2009\n",
    "    )\n",
    "  ):\n",
    "    client = RESTClient(\n",
    "        base_url=BASE_URL,\n",
    "        paginator=PageNumberPaginator(\n",
    "          base_page=STARTING_PAGE,  # Start pagination from page 1\n",
    "          total_path=None  # No total count path, paginate until no more pages\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Iterate over each page of data from the API using the client\n",
    "    for page in client.paginate(ENDPOINT):    # <--- API endpoint for retrieving taxi ride data\n",
    "        yield page   # <--- yield data to manage memory\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_incremental\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(ny_taxi)\n",
    "\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlt pipeline ny_taxi_incremental show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum trip_dropoff_date_time: 2009-06-01 11:48:00+00:00\n"
     ]
    }
   ],
   "source": [
    "with pipeline.sql_client() as client:\n",
    "    res = client.execute_sql(\n",
    "            \"\"\"\n",
    "            SELECT\n",
    "            MIN(trip_dropoff_date_time)\n",
    "            FROM rides;\n",
    "            \"\"\"\n",
    "        )\n",
    "    # print(res)\n",
    "    print(f\"Minimum trip_dropoff_date_time: {res[0][0]}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(pipeline_name=\"ny_taxi_incremental\", destination=\"duckdb\", dataset_name=\"ny_taxi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(ny_taxi)\n",
    "\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure to have `dlt[postgres]` in your environment\n",
    "2. **(Optional)** Check your [docker-compose.yml](docker-compose.yml) file and adjust it accordingly if necessary.\n",
    "3. Run `docker compose up` for `postgres` and `pgadmin` services.\n",
    "4. Check pgAdmin at `localhost:8080` \n",
    "    - `admin@admin.com`, `admin`\n",
    "5. For postgres connection:\n",
    "     - host: `postgres`\n",
    "     - port: `5432`\n",
    "     - database: `ny_taxi_data`\n",
    "     - user: `postgres`\n",
    "     - password: `postgres`\n",
    "\n",
    "![alt text](assets/images/image-2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "# Define the base URL of the API, ENDPOINT, and STARTING_PAGE\n",
    "BASE_URL = \"https://us-central1-dlthub-analytics.cloudfunctions.net\"\n",
    "ENDPOINT = \"data_engineering_zoomcamp_api\"\n",
    "STARTING_PAGE = 1\n",
    "\n",
    "# Define the API resource for NYC taxi data and the incremental cursor\n",
    "@dlt.resource(name=\"rides\", write_disposition=\"append\")   # <--- The name of the resource (will be used as the table name)\n",
    "def ny_taxi(\n",
    "    cursor_date = dlt.sources.incremental(\n",
    "        \"Trip_Dropoff_DateTime\",   # <--- field to track, our timestamp\n",
    "        initial_value=\"2009-06-15\",   # <--- start date June 15, 2009\n",
    "    )\n",
    "):\n",
    "    client = RESTClient(\n",
    "        base_url=BASE_URL,\n",
    "        paginator = PageNumberPaginator(\n",
    "          base_page= STARTING_PAGE,\n",
    "          total_path=None\n",
    "        )\n",
    "    )\n",
    "  \n",
    "    # Iterate over each page of data from the API using the client\n",
    "    for page in client.paginate(ENDPOINT):    # <--- API endpoint for retrieving taxi ride data\n",
    "        yield page   # <--- yield data to manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"postgres_ny_taxi\",\n",
    "    # Credentials usage:\n",
    "    # secrets.toml or ENVs.\n",
    "    destination=\"postgres\",\n",
    "    # For testing purposes eg.:\n",
    "    # destination= dlt.destinations.postgres(\"postgresql://postgres:postgres@localhost:5432/ny_taxi_data\"),\n",
    "    dataset_name=\"postgres_ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_info = pipeline.run(\n",
    "    ny_taxi()\n",
    ")\n",
    "\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postgres Query Results\n",
    "![alt text](assets/images/image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are pretty similar for Bigquery, so lets fasten up a bit.\n",
    "- Make sure to have `dlt[bigquery]` in your environment\n",
    "- Properly config your `ENVs` or `secrets.toml` for GCP credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "@dlt.resource(name=\"rides\", write_disposition=\"append\")\n",
    "def ny_taxi():\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://us-central1-dlthub-analytics.cloudfunctions.net\",\n",
    "        paginator=PageNumberPaginator(\n",
    "            base_page=1,\n",
    "            total_path=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\"data_engineering_zoomcamp_api\"):\n",
    "        yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='taxi_data',\n",
    "    destination='duckdb', # <--- to test pipeline locally\n",
    "    dataset_name='taxi_rides',\n",
    ")\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='taxi_data',\n",
    "    destination='bigquery', # <--- to run pipeline in production\n",
    "    dataset_name='taxi_rides',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>=========================================Extract taxi_data==========================================</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Resources 100%|██████████████████████████████████████████████████████████| 1/1 [00:28&lt;00:00, 0.04/s]</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>rides 10000 [00:25, 394.06/s]                                                                       </pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>=========================================Extract taxi_data==========================================</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Resources 100%|█████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 34.57/s]</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>_dlt_pipeline_state 1 [00:00, 122.78/s]                                                             </pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>=============================Normalize taxi_data in 1739562184.6926608==============================</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Files 100%|██████████████████████████████████████████████████████████████| 2/2 [00:01&lt;00:00, 1.33/s]</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Items 10001 [00:01, 6680.28/s]                                                                      </pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "</style>\n",
       "<div class=\"enlighten\">\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>================================Load taxi_data in 1739562184.6926608================================</pre>\n",
       "  </div>\n",
       "  <div class=\"enlighten-bar\">\n",
       "    <pre>Jobs 100%|███████████████████████████████████████████████████████████████| 2/2 [00:14&lt;00:00, 0.14/s]</pre>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_data\",\n",
    "    destination=\"bigquery\",\n",
    "    dataset_name=\"taxi_rides\",\n",
    "    progress=\"enlighten\", # <--- Install enlighten for better visualization. Otherwise comment this line\n",
    "    dev_mode=True,\n",
    ")\n",
    "\n",
    "info = pipeline.run(ny_taxi)\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check results\n",
    "\n",
    "\n",
    "|![alt text](assets/images/image-4.png)|![alt text](assets/images/image-5.png)|\n",
    "|---|---|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
